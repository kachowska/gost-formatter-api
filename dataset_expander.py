"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞—Ä–∏–∞—Ü–∏–π –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –í–ê–ö

–ù–∞ –æ—Å–Ω–æ–≤–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–æ–∑–¥–∞—ë—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏,
—Å–æ—Ö—Ä–∞–Ω—è—è –¢–û–ß–ù–£–Æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é.
"""

import json
import random
import re
import hashlib
from datetime import datetime
from typing import List, Dict, Tuple

# =============================================
# –°–õ–û–í–ê–†–ò –î–õ–Ø –ì–ï–ù–ï–†–ê–¶–ò–ò –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–• –î–ê–ù–ù–´–•
# =============================================

# –ë–µ–ª–æ—Ä—É—Å—Å–∫–∏–µ –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ —Ñ–∞–º–∏–ª–∏–∏
SURNAMES = [
    # –ë–µ–ª–æ—Ä—É—Å—Å–∫–∏–µ
    "–Ü–≤–∞–Ω–æ—û", "–ö–∞–∑–ª–æ—û", "–ù–æ–≤—ñ–∫", "–ö–∞–≤–∞–ª—ë—û", "–ü–µ—Ç—Ä—ã–∫–∞—û", "–í–∞—Å—ñ–ª–µ—û—Å–∫—ñ", "–ú—ñ–∫–∞–ª–∞–µ—û",
    "–°—ñ–¥–∞—Ä—ç–Ω–∫–∞", "–ë–∞–±—Ä—ã–∫–∞—û", "–ú–∞—Å–ª–æ—û—Å–∫—ñ", "–®—ã—à–∫–æ", "–Ø—Ä–º–æ–ª—ñ–∫", "–ö—É–ø–∞–ª–∞", "–ö–æ–ª–∞—Å",
    "–ë–∞–≥–¥–∞–Ω–æ–≤—ñ—á", "–ú–µ–ª–µ–∂", "–ö–∞—Ä–∞—Ç–∫–µ–≤—ñ—á", "–ë—ã–∫–∞—û", "–ê–¥–∞–º–æ–≤—ñ—á", "–®–∞–º—è–∫—ñ–Ω",
    # –†—É—Å—Å–∫–∏–µ
    "–ò–≤–∞–Ω–æ–≤", "–ü–µ—Ç—Ä–æ–≤", "–°–∏–¥–æ—Ä–æ–≤", "–ö–æ–∑–ª–æ–≤", "–ù–æ–≤–∏–∫–æ–≤", "–ú–æ—Ä–æ–∑–æ–≤", "–í–æ–ª–∫–æ–≤",
    "–°–æ–∫–æ–ª–æ–≤", "–ü–æ–ø–æ–≤", "–õ–µ–±–µ–¥–µ–≤", "–°–µ–º—ë–Ω–æ–≤", "–ï–≥–æ—Ä–æ–≤", "–ü–∞–≤–ª–æ–≤", "–ö—É–∑–Ω–µ—Ü–æ–≤",
    "–°—Ç–µ–ø–∞–Ω–æ–≤", "–ù–∏–∫–æ–ª–∞–µ–≤", "–û—Ä–ª–æ–≤", "–ê–Ω–¥—Ä–µ–µ–≤", "–ú–∞–∫–∞—Ä–æ–≤", "–ó–∞—Ö–∞—Ä–æ–≤",
    "–§–µ–¥–æ—Ä–æ–≤", "–ú–∏—Ö–∞–π–ª–æ–≤", "–ë–µ–ª—è–µ–≤", "–¢–∞—Ä–∞—Å–æ–≤", "–ë–µ–ª–æ–≤", "–ö–æ–º–∞—Ä–æ–≤",
]

# –ò–Ω–∏—Ü–∏–∞–ª—ã
INITIALS = [
    "–ê. –ê.", "–ê. –í.", "–ê. –ò.", "–ê. –ù.", "–ê. –ü.", "–ê. –°.",
    "–í. –ê.", "–í. –í.", "–í. –ò.", "–í. –ú.", "–í. –ù.", "–í. –ü.",
    "–ì. –ê.", "–ì. –í.", "–î. –ê.", "–î. –í.", "–ï. –ê.", "–ï. –í.",
    "–ò. –ê.", "–ò. –í.", "–ò. –ò.", "–ò. –ü.", "–ú. –ê.", "–ú. –í.",
    "–ù. –ê.", "–ù. –í.", "–ù. –ò.", "–ù. –ù.", "–û. –ê.", "–û. –í.",
    "–ü. –ê.", "–ü. –í.", "–ü. –ü.", "–°. –ê.", "–°. –í.", "–°. –ò.",
]

# –ò–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –ë–µ–ª–∞—Ä—É—Å–∏
PUBLISHERS_BY = [
    "–ë–µ–ª–∞—Ä—É—Å–∫–∞—è –Ω–∞–≤—É–∫–∞", "–í—ã—à—ç–π—à–∞—è —à–∫–æ–ª–∞", "–ë–î–£", "–ë–î–¢–£", "–ë–ù–¢–£",
    "–ë–µ–ª–∞—Ä—É—Å—å", "–ù–∞—Ä–æ–¥–Ω–∞—è –∞—Å–≤–µ—Ç–∞", "–ê–≤–µ—Ä—Å—ç–≤", "–ü–æ–ª—ã–º—è", "–ú–∞—Å—Ç–∞—Ü–∫–∞—è –ª—ñ—Ç–∞—Ä–∞—Ç—É—Ä–∞",
    "–Æ–Ω–∏–ø–∞–∫", "–¢—ç—Ö–Ω–∞–ª–æ–≥—ñ—è", "–ì—Ä–î–£", "–í–î–£", "–ú–∞–≥–î–£", "–ë—Ä–î–£",
    "–ë–µ–ª–æ—Ä—É—Å—Å–∫–∞—è –Ω–∞—É–∫–∞", "–ë–µ–ª–æ—Ä—É—Å—Å–∫–∏–π –î–æ–º –ø–µ—á–∞—Ç–∏", "–ü—Ä–∞–≤–æ –∏ —ç–∫–æ–Ω–æ–º–∏–∫–∞",
    "–ß–µ—Ç—ã—Ä–µ —á–µ—Ç–≤–µ—Ä—Ç–∏", "–ö–Ω–∏–∂–Ω—ã–π –î–æ–º", "–ú–µ–¥–∏—Å–æ–Ω—Ç", "–ë–µ–ª–æ—Ä—É—Å—Å–∫–∏–π –¥–æ–º –ø–µ—á–∞—Ç–∏",
]

# –ò–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–æ—Å—Å–∏–∏
PUBLISHERS_RU = [
    "–ù–∞—É–∫–∞", "–ü—Ä–æ—Å–≤–µ—â–µ–Ω–∏–µ", "–í—ã—Å—à–∞—è —à–∫–æ–ª–∞", "–Æ—Ä–∞–π—Ç", "–ò–ù–§–†–ê-–ú",
    "–ê–∫–∞–¥–µ–º–∏—è", "–î—Ä–æ—Ñ–∞", "–ü–∏—Ç–µ—Ä", "–ë–•–í-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–§–ª–∏–Ω—Ç–∞",
    "–î–∞—à–∫–æ–≤ –∏ –ö¬∞", "URSS", "–ò–∑–¥–∞—Ç–µ–ª—å—Å–∫–∏–π –¥–æ–º –ú–ì–£", "–°—Ç–∞—Ç—É—Ç",
    "–ü—Ä–æ—Å–ø–µ–∫—Ç", "–ö–Ω–æ–†—É—Å", "–≠–∫—Å–º–æ", "–ê–°–¢", "–ú–∞–Ω–Ω, –ò–≤–∞–Ω–æ–≤ –∏ –§–µ—Ä–±–µ—Ä",
]

# –ì–æ—Ä–æ–¥–∞
CITIES_BY = ["–ú—ñ–Ω—Å–∫", "–ú–∏–Ω—Å–∫", "–ú–Ω.", "–ì–æ–º–µ–ª—å", "–ë—Ä—ç—Å—Ç", "–ì—Ä–æ–¥–Ω–∞", "–í—ñ—Ü–µ–±—Å–∫", "–ú–∞–≥—ñ–ª—ë—û"]
CITIES_RU = ["–ú.", "–ú–æ—Å–∫–≤–∞", "–°–ü–±.", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥"]

# –ñ—É—Ä–Ω–∞–ª—ã
JOURNALS = [
    "–í–µ—Å—Ü—ñ –ù–ê–ù –ë–µ–ª–∞—Ä—É—Å—ñ", "–î–æ–∫–ª–∞–¥—ã –ù–ê–ù –ë–µ–ª–∞—Ä—É—Å–∏", "–ñ—É—Ä–Ω–∞–ª –ë–ì–£",
    "–í–µ—Å—Ç–Ω–∏–∫ –ë–ù–¢–£", "–ò–∑–≤–µ—Å—Ç–∏—è –ù–ê–ù –ë–µ–ª–∞—Ä—É—Å–∏", "–ù–∞—É–∫–∞ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
    "–í–æ–ø—Ä–æ—Å—ã —ç–∫–æ–Ω–æ–º–∏–∫–∏", "–ü—Ä–æ–±–ª–µ–º—ã —Ç–µ–æ—Ä–∏–∏ –∏ –ø—Ä–∞–∫—Ç–∏–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
    "–≠–∫–æ–Ω–æ–º–∏—Å—Ç", "–§–∏–Ω–∞–Ω—Å—ã –∏ –∫—Ä–µ–¥–∏—Ç", "–ü—Ä–∞–≤–æ –∏ —ç–∫–æ–Ω–æ–º–∏–∫–∞",
    "–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ –∏ –ø—Ä–∞–≤–æ", "–ñ—É—Ä–Ω–∞–ª —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞",
]

# –ù–∞–∑–≤–∞–Ω–∏—è –∫–Ω–∏–≥/—Å—Ç–∞—Ç–µ–π (—à–∞–±–ª–æ–Ω—ã)
TITLE_TEMPLATES = {
    "book": [
        "–û—Å–Ω–æ–≤—ã {field}",
        "{Field} –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö",
        "–¢–µ–æ—Ä–∏—è –∏ –ø—Ä–∞–∫—Ç–∏–∫–∞ {field_gen}",
        "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è {field_gen}",
        "{Field}: —É—á–µ–±–Ω–æ–µ –ø–æ—Å–æ–±–∏–µ",
        "–í–≤–µ–¥–µ–Ω–∏–µ –≤ {field_acc}",
        "–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã {field_gen}",
        "{Field} –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
        "–†–∞–∑–≤–∏—Ç–∏–µ {field_gen} –≤ XXI –≤–µ–∫–µ",
    ],
    "article": [
        "–ö –≤–æ–ø—Ä–æ—Å—É –æ {field_prep}",
        "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ {field_gen}",
        "–ê–Ω–∞–ª–∏–∑ {field_gen} –≤ —É—Å–ª–æ–≤–∏—è—Ö –≥–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏–∏",
        "–ü—Ä–æ–±–ª–µ–º—ã –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è {field_gen}",
        "–ù–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ {field_dat}",
        "–û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ {field_gen}",
    ]
}

FIELDS = [
    ("—ç–∫–æ–Ω–æ–º–∏–∫–∞", "—ç–∫–æ–Ω–æ–º–∏–∫–∏", "—ç–∫–æ–Ω–æ–º–∏–∫–µ", "—ç–∫–æ–Ω–æ–º–∏–∫—É", "—ç–∫–æ–Ω–æ–º–∏–∫–µ"),
    ("–ø—Ä–∞–≤–æ", "–ø—Ä–∞–≤–∞", "–ø—Ä–∞–≤—É", "–ø—Ä–∞–≤–æ", "–ø—Ä–∞–≤–µ"),
    ("–ø–µ–¥–∞–≥–æ–≥–∏–∫–∞", "–ø–µ–¥–∞–≥–æ–≥–∏–∫–∏", "–ø–µ–¥–∞–≥–æ–≥–∏–∫–µ", "–ø–µ–¥–∞–≥–æ–≥–∏–∫—É", "–ø–µ–¥–∞–≥–æ–≥–∏–∫–µ"),
    ("–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—é", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏–∏"),
    ("—Å–æ—Ü–∏–æ–ª–æ–≥–∏—è", "—Å–æ—Ü–∏–æ–ª–æ–≥–∏–∏", "—Å–æ—Ü–∏–æ–ª–æ–≥–∏–∏", "—Å–æ—Ü–∏–æ–ª–æ–≥–∏—é", "—Å–æ—Ü–∏–æ–ª–æ–≥–∏–∏"),
    ("—Ñ–∏–ª–æ—Å–æ—Ñ–∏—è", "—Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏", "—Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏", "—Ñ–∏–ª–æ—Å–æ—Ñ–∏—é", "—Ñ–∏–ª–æ—Å–æ—Ñ–∏–∏"),
    ("–∏—Å—Ç–æ—Ä–∏—è", "–∏—Å—Ç–æ—Ä–∏–∏", "–∏—Å—Ç–æ—Ä–∏–∏", "–∏—Å—Ç–æ—Ä–∏—é", "–∏—Å—Ç–æ—Ä–∏–∏"),
    ("—Ñ–∏–ª–æ–ª–æ–≥–∏—è", "—Ñ–∏–ª–æ–ª–æ–≥–∏–∏", "—Ñ–∏–ª–æ–ª–æ–≥–∏–∏", "—Ñ–∏–ª–æ–ª–æ–≥–∏—é", "—Ñ–∏–ª–æ–ª–æ–≥–∏–∏"),
    ("–±–∏–æ–ª–æ–≥–∏—è", "–±–∏–æ–ª–æ–≥–∏–∏", "–±–∏–æ–ª–æ–≥–∏–∏", "–±–∏–æ–ª–æ–≥–∏—é", "–±–∏–æ–ª–æ–≥–∏–∏"),
    ("—Ñ–∏–∑–∏–∫–∞", "—Ñ–∏–∑–∏–∫–∏", "—Ñ–∏–∑–∏–∫–µ", "—Ñ–∏–∑–∏–∫—É", "—Ñ–∏–∑–∏–∫–µ"),
    ("—Ö–∏–º–∏—è", "—Ö–∏–º–∏–∏", "—Ö–∏–º–∏–∏", "—Ö–∏–º–∏—é", "—Ö–∏–º–∏–∏"),
    ("–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞", "–º–∞—Ç–µ–º–∞—Ç–∏–∫–∏", "–º–∞—Ç–µ–º–∞—Ç–∏–∫–µ", "–º–∞—Ç–µ–º–∞—Ç–∏–∫—É", "–º–∞—Ç–µ–º–∞—Ç–∏–∫–µ"),
    ("–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∞", "–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–∏", "–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ", "–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫—É", "–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫–µ"),
    ("–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç", "–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞", "–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç—É", "–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç", "–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–µ"),
    ("–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ"),
]

# =============================================
# –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò
# =============================================

def random_author() -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –§–∞–º–∏–ª–∏—è, –ò. –û."""
    return f"{random.choice(SURNAMES)}, {random.choice(INITIALS)}"

def random_author_full() -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–≤—Ç–æ—Ä–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ò. –û. –§–∞–º–∏–ª–∏—è"""
    initials = random.choice(INITIALS)
    surname = random.choice(SURNAMES)
    return f"{initials} {surname}"

def random_year(min_year: int = 2015, max_year: int = 2025) -> int:
    return random.randint(min_year, max_year)

def random_pages() -> str:
    return str(random.randint(80, 500))

def random_page_range() -> str:
    start = random.randint(5, 200)
    end = start + random.randint(5, 30)
    return f"{start}‚Äì{end}"

def random_publisher(country: str = "BY") -> str:
    if country == "BY":
        return random.choice(PUBLISHERS_BY)
    return random.choice(PUBLISHERS_RU)

def random_city(country: str = "BY") -> str:
    if country == "BY":
        return random.choice(CITIES_BY)
    return random.choice(CITIES_RU)

def random_volume() -> str:
    return str(random.randint(1, 50))

def random_issue() -> str:
    return str(random.randint(1, 12))

def gen_id(text: str, idx: int) -> str:
    return hashlib.md5(f"{text[:30]}_{idx}".encode()).hexdigest()[:12]


class DatasetExpander:
    """–†–∞—Å—à–∏—Ä–∏—Ç–µ–ª—å –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    
    def __init__(self, original_dataset_path: str):
        with open(original_dataset_path, 'r', encoding='utf-8') as f:
            self.original = json.load(f)
        
        self.records = self.original.get('records', [])
        self.expanded = []
        self.idx = 0
    
    def create_variation(self, record: Dict, variation_num: int) -> Dict:
        """–°–æ–∑–¥–∞—ë—Ç –≤–∞—Ä–∏–∞—Ü–∏—é –∑–∞–ø–∏—Å–∏, —Å–æ—Ö—Ä–∞–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
        formatted = record['formatted_output']
        source_type = record['source_type']
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∑–∞–º–µ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        new_formatted = formatted
        
        # 1. –ó–∞–º–µ–Ω—è–µ–º –≥–æ–¥–∞
        years = re.findall(r'\b(19|20)\d{2}\b', new_formatted)
        for year in years:
            new_year = str(random_year())
            new_formatted = new_formatted.replace(year, new_year, 1)
        
        # 2. –ó–∞–º–µ–Ω—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (XXX —Å.)
        page_match = re.search(r'(\d{2,3})\s*—Å\.', new_formatted)
        if page_match:
            new_formatted = new_formatted.replace(
                page_match.group(0), 
                f"{random_pages()} —Å."
            )
        
        # 3. –ó–∞–º–µ–Ω—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü (–°. XX‚ÄìYY)
        range_match = re.search(r'–°\.\s*\d+[‚Äì‚Äî-]\d+', new_formatted)
        if range_match:
            new_formatted = new_formatted.replace(
                range_match.group(0),
                f"–°. {random_page_range()}"
            )
        
        # 4. –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–º (–¢. X)
        vol_match = re.search(r'–¢\.\s*\d+', new_formatted)
        if vol_match:
            new_formatted = new_formatted.replace(
                vol_match.group(0),
                f"–¢. {random_volume()}"
            )
        
        # 5. –ó–∞–º–µ–Ω—è–µ–º –Ω–æ–º–µ—Ä (‚Ññ X)
        issue_match = re.search(r'‚Ññ\s*\d+', new_formatted)
        if issue_match:
            new_formatted = new_formatted.replace(
                issue_match.group(0),
                f"‚Ññ {random_issue()}"
            )
        
        # 6. –ó–∞–º–µ–Ω—è–µ–º –∞–≤—Ç–æ—Ä–æ–≤ (–§–∞–º–∏–ª–∏—è, –ò. –û.)
        author_pattern = r'([–ê-–Ø–ÅA-Z][–∞-—è—ëa-z]+),\s+([–ê-–Ø–ÅA-Z]\.\s*[–ê-–Ø–ÅA-Z]?\.?)'
        authors_found = re.findall(author_pattern, new_formatted)
        
        author_mapping = {}
        for surname, initials in authors_found:
            if surname not in author_mapping:
                new_surname = random.choice(SURNAMES)
                new_initials = random.choice(INITIALS)
                author_mapping[surname] = (new_surname, new_initials)
        
        for old_surname, (new_surname, new_initials) in author_mapping.items():
            # –ó–∞–º–µ–Ω—è–µ–º "–§–∞–º–∏–ª–∏—è, –ò. –û."
            new_formatted = re.sub(
                rf'{old_surname},\s+[–ê-–Ø–ÅA-Z]\.\s*[–ê-–Ø–ÅA-Z]?\.?',
                f'{new_surname}, {new_initials}',
                new_formatted
            )
            # –ó–∞–º–µ–Ω—è–µ–º "–ò. –û. –§–∞–º–∏–ª–∏—è"
            new_formatted = re.sub(
                rf'[–ê-–Ø–ÅA-Z]\.\s*[–ê-–Ø–ÅA-Z]?\.\s*{old_surname}',
                f'{new_initials} {new_surname}',
                new_formatted
            )
        
        return {
            'id': gen_id(new_formatted, self.idx),
            'source_type': source_type,
            'country_standard': 'BY',
            'formatted_output': new_formatted,
            'is_variation': True,
            'original_id': record.get('id', ''),
            'variation_number': variation_num
        }
    
    def expand(self, target_count: int = 1000, variations_per_record: int = 8) -> List[Dict]:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –¥–æ —Ü–µ–ª–µ–≤–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
        
        Args:
            target_count: –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            variations_per_record: –ú–∞–∫—Å. –≤–∞—Ä–∏–∞—Ü–∏–π –Ω–∞ –æ–¥–Ω—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å
        """
        self.expanded = []
        self.idx = 0
        
        # –í–∫–ª—é—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–∫–æ–ø–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –º—É—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª)
        for record in self.records:
            record_copy = record.copy()
            record_copy['is_variation'] = False
            self.expanded.append(record_copy)
            self.idx += 1
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –≤–∞—Ä–∏–∞—Ü–∏–π (–∏—Å–∫–ª—é—á–∞–µ–º unknown)
        records_to_vary = [r for r in self.records if r.get('source_type') != 'unknown']
        
        if not records_to_vary:
            return self.expanded
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ —Å —É—á—ë—Ç–æ–º variations_per_record
        variation_counts = {r.get('id', i): 0 for i, r in enumerate(records_to_vary)}
        
        while len(self.expanded) < target_count:
            for record in records_to_vary:
                if len(self.expanded) >= target_count:
                    break
                
                record_id = record.get('id', '')
                current_count = variation_counts.get(record_id, 0)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –≤–∞—Ä–∏–∞—Ü–∏–π –¥–ª—è –¥–∞–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
                if current_count >= variations_per_record:
                    continue
                
                variation = self.create_variation(record, current_count)
                self.expanded.append(variation)
                self.idx += 1
                variation_counts[record_id] = current_count + 1
            
            # –ï—Å–ª–∏ –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞, —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫–∏
            if all(c >= variations_per_record for c in variation_counts.values()):
                variation_counts = {k: 0 for k in variation_counts}
        
        return self.expanded
    
    def save(self, output_path: str, records: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç"""
        # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        type_stats = {}
        originals = 0
        variations = 0
        
        for r in records:
            t = r.get('source_type', 'unknown')
            type_stats[t] = type_stats.get(t, 0) + 1
            if r.get('is_variation'):
                variations += 1
            else:
                originals += 1
        
        dataset = {
            'metadata': {
                'source': 'vak.gov.by + generated variations',
                'generated_at': datetime.now().isoformat(),
                'total_records': len(records),
                'original_records': originals,
                'generated_variations': variations,
                'type_distribution': type_stats
            },
            'records': records
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        
        return dataset['metadata']


if __name__ == "__main__":
    print("üîÑ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –í–ê–ö...")
    
    expander = DatasetExpander('vak_training_dataset.json')
    print(f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(expander.records)}")
    
    # –†–∞—Å—à–∏—Ä—è–µ–º –¥–æ 1000 –∑–∞–ø–∏—Å–µ–π
    expanded = expander.expand(target_count=1000)
    print(f"–ü–æ—Å–ª–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: {len(expanded)}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    metadata = expander.save('vak_training_dataset_expanded.json', expanded)
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
    print(f"–û—Ä–∏–≥–∏–Ω–∞–ª–æ–≤: {metadata['original_records']}")
    print(f"–í–∞—Ä–∏–∞—Ü–∏–π: {metadata['generated_variations']}")
    print(f"–í—Å–µ–≥–æ: {metadata['total_records']}")
    
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
    for t, c in sorted(metadata['type_distribution'].items(), key=lambda x: -x[1])[:10]:
        print(f"  {t}: {c}")
